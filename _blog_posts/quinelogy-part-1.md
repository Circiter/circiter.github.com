---
layout: post
title: "Занимательное квайноводство. Часть I."
xdate: "июль, 2020"
lastedit: "ноябрь, 2020"
sig: true
toc: true
tags: неподвижные-точки sed эзотерика программирование квайноводство теория-вычислимости математика философия саморепликация
abstract: В этом сообщении (в первой части серии сообщений), после краткого введения в некоторые 
          основы теории вычислимости, в основном описываются результаты простого эксперимента по 
          автоматизированному конструированию квайна с использованием второй рекурсивной теоремы 
          Клини.
          
          В качестве целевого языка выбран язык поточного редактора [GNU] sed. Изложение, 
          однако, не специфично для этого языка и может трактоваться в более широком контексте. 
          Фактически, в предлагаемом цикле сообщений излагаются некоторые подходы к 
          систематическому конструированию квайнов.
---

# Введение в квайнологию

Всем известно <<стандартное>> упражнение в программировании, заключающееся в написании 
программы, печатающей свой собственный текст. За такими самореплицирующимися программами 
достаточно давно закрепилось название <<квайн>> (также встречаются варианты 
написания/произношения <<куайн>>, <<квин>>, <<куин>>) введенное в известной книге Хофштадтера 
[26] в честь философа Куайна (Уиллард Ван Орман Куайн = Willard Van Orman Quine) и его 
<<парадокса Куайна>> [15].

Сами квайны при этом появились раньше. Может быть их историю следовало бы вести с работ фон 
Неймана по самореплицирующимся [клеточным] автоматам [9, 48] или даже с работ Чёрча и Хаскеля...

Квайны являются немного парадоксальными программами, в соответствии с бытовой интуицией не 
могущими существовать, -- ведь может показаться, что программа не может вывести текст, имеющий 
длину, равную длине самой программы (должно остаться место для кода, выполняющего печать). И тем 
не менее они существуют (и не требуют сжатия данных, которое, в соответствии с фундаментальной 
теоремой компрессии, не всегда возможно).

Более того, теория вычислимости говорит, что квайны можно написать на *любом* [достаточно 
выразительном] языке программирования. На деле, конечно, сложность написания и размер 
результирующего кода сильно варьируются от языка к языку.

В качестве примеров квайнов можно привести такие поделки (авторы мне не известны):

Квайн на lisp:
```lisp
((lambda (x)
  (list x (list (quote quote) x)))
(quote
  (lambda (x)
    (list x (list (quote quote) x)))))
```

Квайн на стековом rpn-языке форт (forth):
```forth
s" 2dup 115 emit 34 emit 32 emit type 34 emit type cr bye"2dup 115 emit 34 emit 32 emit type 34 emit type cr bye
```

(Это одна длинная строка, могущая отображаться на нескольких экранных строках.)

Квайн на экспериментальном функциональном стековом rpn-языке joy [32]:
```
"dup.putchars.10 putch."
dup.putchars.10 putch.
```

Квайн для $\lambda$-исчисления(почти то же, что и выше на lisp): $$(\lambda x. x x) (\lambda x. 
x x)$$

В стандартной библиотеке языка C есть функция форматированного вывода `printf`, которая может 
быть использована [в качестве суррогата $S^m_n$-функции] для внедрения текста программы в него 
самого; что-то вроде `printf(f, f)`, только с учетом технических сложностей с вложенными 
кавычками для обрамления строк. По этому принципу построен такой известный однострочный 
миниквайн на C (здесь не указан заголовочный файл `stdio.h`, в котором определена `printf`, но в 
таком виде этот код всё-равно компилируется и работает):

```c
char*f="char*f=%c%s%c;main(){printf(f,34,f,34,10);}%c";main(){printf(f,34,f,34,10);}
```

Многие квайны (в т.ч. большинство из приведенных выше) злоупотребляют экранированием строк, 
специальными кодами символов (зависящими от используемой в системе кодировки, e.g. ASCII) и 
библиотечными функциями подстановки (замены подстрок), <<скрывающими>> существенную часть 
происходящих процессов. <<Идеологически>> более чистым подходом представляется ограничение 
строковых манипуляций конкатенацией строк при одновременной минимизации экранирований. Неплохим 
образчиком подобной стратегии написания квайнов является квайн (на pascal'е) от Dan Hoey (взятый 
мною из [50]):

```
program s;const bbb='program s;const bbb';a='a';b='b';bb=');writeln(';
aa='''';ab='=''';ba=''';';
aaa='begin writeln(bbb,ab,bbb,ba,a,ab,a,ba,b,ab,b,ba,b,b,ab,bb,ba';
aba='a,a,ab,aa,aa,ba,a,b,ab,ab,aa,ba,b,a,ab,aa,ba,ba';
abb='a,a,a,ab,aaa,ba);writeln(a,b,a,ab,aba,ba);writeln(a,b,b,ab,abb,ba';
baa='b,a,a,ab,baa,ba);writeln(b,a,b,ab,bab,ba);writeln(aaa,bb';
bab='aba,bb);writeln(abb);writeln(bb,baa);writeln(bb,bab)end.';
begin writeln(bbb,ab,bbb,ba,a,ab,a,ba,b,ab,b,ba,b,b,ab,bb,ba);writeln(
a,a,ab,aa,aa,ba,a,b,ab,ab,aa,ba,b,a,ab,aa,ba,ba);writeln(
a,a,a,ab,aaa,ba);writeln(a,b,a,ab,aba,ba);writeln(a,b,b,ab,abb,ba
);writeln(b,a,a,ab,baa,ba);writeln(b,a,b,ab,bab,ba);writeln(aaa,bb
);writeln(aba,bb);writeln(abb);writeln(bb,baa);writeln(bb,bab)end.

```

(N.B., на самом деле этот квайн записывается в одну строку.)

Неплохое введение в написание квайнов можно найти, например, в [1, 30]; а неплохую коллекцию 
-- в [30, 18].

## Искусство *versus* ремесло

Основной причиной проведения небольшого эксперимента, ставшего основой настоящего сообщения, 
явилось желание написать, или, точнее говоря, попробовать написать квайн на входном языке 
поточного редактора sed. Применение поисковых систем для поиска уже имеющихся решений привело к 
обнаружению квайна `quine.sed` [17] из <<музея квайнов>> [18] (автор: Tsuyusato Kitsune):

{% highlight plaintext %}
s/^/s11^113311;h;s221[1]221122g;s112[2]11222211g;G;s11^22([^3]*22)3322([^22n]*22).22(.*22)$1122122322211/;h;s\1[1]\/\g;s/2[2]/\\/g;G;s/^\([^3]*\)33\([^\n]*\).\(.*\)$/\1\3\2/
{% endhighlight %}

(N.B., это одна строка текста.)

Вряд ли у меня вышло бы улучшить (например, сократить) этот квайн. Более того, самостоятельная 
попытка написать нечто подобное тоже не увенчалась успехом. Поэтому было принято решение 
действовать более систематичным образом и воспользоваться уже имеющимся в распоряжении 
математики арсеналом готовых теоретических средств.

Вторая рекурсивная теорема Клини имеет своим следствием утверждение о существовании квайна для 
любого языка программирования, а конструктивный характер её доказательства дает готовый рецепт 
для написания такого <<саморепликатора>> (ниже об этом будет написано подробнее).

Стандартные пособия по теории вычислимости нередко не ограничиваются лишь утверждениями о 
существовании квайнов, и даже приводят конкретные примеры их конструирования, правда, выбирая 
при этом, как правило, <<удобные>> языки программирования, например, прагматические реализации 
$\lambda$-исчисления, такие как lisp и его производные.

Попадались интересные исключения, e.g. [35, 36], но для слишком абстрактных машин. Поэтому я 
решил повторить классический эксперимент с конструированием квайна на основе доказательства 
рекурсивной теоремы Клини, но выполнить этот эксперимент на языке sed (кстати, всё-равно 
оказавшемся достаточно удобным для этой задачи, в основном из-за возможности объединения 
скриптов их конкатенацией).

**Обновление (август, 2020):** <em>Уже после написания черновика этого сообщения, примеры 
применения второй рекурсивной теоремы Клини к практическим языкам программирования всё-таки 
отыскались на просторах интернета. В [53] можно найти генератор квайнов на JavaScript 
(ECMAScript), а в [54] -- похожий генератор, но для C++. Причем в последнем примере, указанная 
утилита позиционируется как достаточно общий инструмент для добавления рефлексивных возможностей 
к языку, с ограниченной штатной рефлексией (i.e., сгенерированная программа может как просто 
печатать свой собственный текст, так и вычислять произвольные функции от него, скажем, находить 
свою длину).</em>

<em>Возможно читателю также будет интересна аналогичная утилита [55], преобразующая произвольную 
программу на C в квайн.</em>


Результаты эксперимента говорят о возможности автоматической, или <<нетворческой>> генерации 
квайнов, в том числе и на sed.

## Эффективность и выбор названия серии сообщений.

Быть может некоторым показалось бы несколько более благозвучным слово вроде <<квайноделия>>, но 
<<квайноводство>> подходит куда лучше... От части потому, что, как и обещают стандартные вводные 
курсы по теории вычислимости, квайны, конструируемые прямым применением [второй рекурсивной] 
теоремы Клини, обычно получаются, мягко говоря, <<неэффективными>>, как по времени, так и по 
пространству. Ещё одной метрикой эффективности может быть отношения объёмов данных и кода; 
специально я не исследовал этот вопрос, так что не могу сказать как с этим обстоят дела у 
автоматически сгенерированных квайнов, но неверняка неоптимально. :)

## Постановка задачи

Пусть квайн хранится в исполняемом файле `quine`, полученным компиляцией его исходного текста из 
файла `quine.source`. Для меня достаточно чисто формального выполнения следующего теста:

```sh
./quine any_argument > quine.output
diff quine.source quine.output
```

или аналогичного теста для интерпретируемого языка (здесь `interpreter` -- исполняемый файл 
интерпретатора или аналогичная внутренняя команда оболочки):

```sh
interpreter quine.source any_argument > quine.output
diff quine.source quine.output
```

Для sed это соответствует следующему тесту:

```sh
echo any_argument | sed -f quine.sed > quine.output
diff quine.sed quine.output
```

Проверку на тривиальность (в частности, на пустоту) можно выполнять и <<вручную>> (из-за 
плохой формализуемости и некоторой субъективности).

То есть, квайн конечного размера (скажем, помещающийся на жесткий диск) должен напечать свой 
собственный текст за конечное (и разумное время). Абсолютно не важно, будут ли исходный текст и 
скомпилированная программа весить несколько килобайт или несколько мегабайт. Гораздо важнее, 
чтобы квайн был истинным, т.е. был непустым, <<содержательным>>, и не использовал <<нечестные>> 
рефлексивные возможности (вроде чтения своего исходного текста из файла).

# Вводные замечания

В теории вычислимости особо важное место занимают несколько интересных теорем о вычислимых 
функциях. В этом сообщении я хотел бы кратко рассказать об этих теоремах и о некоторых их 
применениях.

Для некоторой программы с текстом $p$ соответствующую ей (частичную) вычислимую функцию обычно 
обозначают как $\varphi_p$, однако, воизбежание нагромождения нижних индексов далее будет 
использоваться несколько более удобное обозначение, широко применяющееся при изучении семантики 
языков программирования, а именно $\llbracket p\rrbracket$.

Обычно, в теории алгоритмов (теории вычислимости, теории рекурсии) говорят о [гёделевском] 
номере программы, а не о её тексте, но далее будет использоваться более наглядное и привычное, 
по крайней мере для программистов, слово *текст*, иногда даже *исходный код*, без прямого отсыла 
к понятию *нумерации* из теории вычислимости. Более того, вразрез с традиционным 
словоупотреблением, в настоящем сообщении нередко программа и её текст будут отождествляться, -- 
здесь это просто одно и то же. (Краткости и простоты ради, это сообщение будет вообще несколько 
неформальным и не строгим.)

При одновременном рассмотрении нескольких языков программирования, как, например, при 
работе с трансляторами, можно указывать язык программирования в нижнем индексе 
семантических скобок, e.g., $\llbracket\cdot\rrbracket_\varphi$. (Кстати, в литературе 
встречается и более необычная нотация, например, вообще не используюшая какие-либо индексы и 
скобки, для экономии места.)

Символом $\bot$ будет обозначено незавершающееся вычисление, т.е. $\bot$ -- это значение 
бесконечного цикла. Равенство $\llbracket a\rrbracket=\llbracket b\rrbracket$ есть сокращение 
для $\forall x\ \llbracket a\rrbracket(x) = \llbracket b\rrbracket(x)$. (Подразумевается, что 
для некоторых $x$, может выполнятся $\llbracket a\rrbracket(x)=\bot$ и $\llbracket 
b\rrbracket(x)=\bot$.)

## Теорема об универсальной функции

Сначала хотелось бы упомянуть теорему о существовании универсальной программы, а фактически о 
возможности написания интерпретаторов для любых подходящих (Тьюринг-полных) языков 
программирования, причем подразумевается, что интерпретатор пишется на его же входном языке. 
Более формально, эта теорема утверждает, что существуют вычислимая функция --- *универсальная 
функция* --- $u$, а также соответствующая ей программа-интерпретатор $I$, такие, что для любой 
программы $p$, интерпретатор может быть запущен с несколькими аргументами, первый из которых 
равен $p$, а оставшиеся суть просто аргументы для этой программы. Так запущенный интерпретатор 
должен возвратить тот же результат, что и сама программа $p$ при тех же аргументах.

То есть, $\exists u, I\colon\forall p\forall x\ u(p, x)=\llbracket I\rrbracket(p, x)=\llbracket 
p\rrbracket(x)$.

**Набросок доказательства.**

Доказательство может проводится просто предъявлением готового интерпретатора в виде машины 
Тьюринга, т.е. путем построение т.н. универсальной машины Тьюринга, симулирующей работу любой 
другой машины Тьюринга. Понятно, что можно использовать и любую другую модель вычислений, e.g., 
$\lambda$-исчисление. Но здесь, для краткости, аргументация будет менее конструктивной и более 
абстрактной.

Естественно считать программами куски текста (i.e., строки) на некотором языке программирования. 
Пусть на строках определён обычный порядок $<$, а именно, для строк $s$ и $r$ выполняется $s<r$ 
если $|s|<|r|$ (i.e., сравниваются длины) или, в случае $|s|=|r|$, если $s$ лексикографически 
предшествует $r$. Т.о., все программы можно отсортировать относительно $<$, получив в результате 
упорядоченную последовательность $\{p_i\}$. Будем считать, что для любой программы $p_i$ можно 
построить специализированное вычислительное устройство $e_i$, преобразующее входные данные $x$ в 
выходные $e_i[x]$ (эта нотация, по-факту, означает запуск устройства $e_i$ с аргументом $x$).

Теперь можно определить функцию $u(n, x)=e_n[x]$. Полнота по Тьюрингу позволяет утверждать, что 
для любой вычислимой функции $f$ существует вычислительное устройство $e$, такое, что $\forall 
x\ e[x]=f(x)$; а раз в последовательности $\{e_i\}$ есть вычислительные устройства для всех 
программ, то найдётся число $n$, такое, что $e_n=e$. Получается, что $u(n, x)=e[x]=f(x)$, т.е., 
функция $u$ может использоваться вместо любой вычислимой функции $f$ если известен её номер $n$; 
другими словами, $u$ -- универсальная функция.

Осталось показать, что $u$ вычислима. Для этого надо написать интерпретатор $I$ и сконструирвать 
соответствующее вычислительное устройство $\mathcal{I}$, по первому аргументу $n$ командной 
строки извлекающее устройство с индексом $n$ из последовательности $\{e_i\}$ и запускающее его, 
передавая ему при запуске остальные свои аргументы. Т.е., должно выполняться $\mathcal{I}[n, 
x]=e_n[x]$. Видно, что $\mathcal{I}$ -- устройство, вычисляющее $u$, а $I$ -- программа, это 
делающая. Таким образом, $u$ -- вычислимая универсальная функция. $\blacksquare$

N.B., сама теорема не зависит от языка программирования и требует лишь его полноты по Тьюрингу, 
т.е. возможности написать для любой вычислимой функции программу, её вычисляющую; да, звучит 
немного тавтологично, и, тем не менее, есть языки не являющиеся Тьюринг-полными: на них нельзя 
реализовать некоторые программы, легко пишущиеся на каком-нибудь универсальном, Тьюринг-полном 
языке. Существуют ли программы, не могущие быть перенесены на машину Тьюринга или любую 
эквивалентную ей машину, но могущие выполняться на каком-нибудь другом компьютере -- интересный 
философский вопрос; тезис Чёрча-Тьюринга говорит, что нет, таких программ не существует (и 
действительно, все известные теоретические конструкции более мощных компьютеров конфликтуют с 
теми или иными физическими законами и в это вселенной работать не могут).

А вот существование вычислимой универсальной функции, по-видимому, не влечёт за собой полноты по 
Тьюрингу -- если взять некоторый подходящий неуниверсальный язык, то можно действовать как в 
вышеприведенном наброске доказательства, т.е. можно сгенерировать и отсортировать все программы 
[для этого языка] и вычислительные устройства, а потом определить функцию, выбирающую и 
использующую нужное устройство по его номеру. Если выбранный язык будет достаточно богат, чтобы 
на нём можно было выразить такой выбор и запуск, то мы получим вычислимую универсальную функцию, 
правда, универсальную не для всех вычислимых функций, а только для функций, реализуемых на таком 
языке.

Фактически, теорема об универсальной функции говорит, что частичная (т.е. не являющаяся всюду 
определённой) функция $\llbracket x \rrbracket(y_0,\ldots)$ от аргументов $y_0,\ldots$ сама 
является вычислимой (или т.н. частично рекурсивной) функцией $f(x, y_0, \ldots)$ от аргументов 
$x, y_0, \ldots$ (добавился ещё один аргумент).

Использование теоремы об универсальной функции в данном сообщении будет весьма ограниченным; 
здесь без неё можно было бы и обойтись (если не считать теорему Роджерса, см. ниже). И всё-же 
она в определённые моменты будет важна. Кроме этого, стоит обратить внимание на использованное в 
доказательстве разделение на программы (тексты программ), вычислительные устройства и их номера, 
-- нам пришлось использовать устройства, чтобы подчеркнуть механистичность и физическую 
реализуемость вычислений, текстовое представление программ, чтобы иметь возможность сортировать 
и нумеровать программы/устройства, и, наконец, пришлось выбрать конкретный (но не единственный) 
способ такой нумерации с помощью сортировки по возрастанию относительно порядка $<$.

В дальнейшем такое разделение представлений будет лишним и поэтому, как я уже говорил ранее, 
тексты программ, программы и их номера будут отождествляться. Сам конкретный способ нумерации 
можно будет считать заданием языка программирования, хотя на практике же удобно отождествлять 
язык программирования с семантической функцией $\llbracket p\rrbracket\colon p\mapsto D^D$, 
сопоставляющей программе $p$ функцию $D\to D$, где $D$ -- множество, над которым определены 
вычислимые функции (в большинстве случаев можно считать $D=\mathbb{N}$) или с парой $(D, 
\llbracket\cdot\rrbracket)$. (В следующей части этой серии сообщений, я постараюсь уделить 
должное внимание понятию нумерации, но здесь оно свою полезность, похоже, пока исчерпало.)

N.B., Также подразумевается, что паре значений $(x, y)$ можно сопоставить взаимно однозначным 
образом $N_{xy}$ (причем отображение $(x, y)\mapsto N_{xy}$ вычислимо). Это позволяет определять 
функции с большим количеством аргументов через функции с меньшим количеством, например 
$\varphi(p, x, y)=\varphi(p, (x, y))=\varphi(p, N_{xy})$. Т.о., теоретически можно вообще 
обходиться только одноместными функциями, но из соображений удобства, к такому минимализму 
прибегать, надеюсь, не придётся.

## S-m-n теорема Клини

Другой, не менее важной теоремой является т.н. $S^m_n$-теорема (известная также как теорема о 
параметризации или итеративная теорема) [14, 3], утверждающая, что может быть написана 
программа, уменьшающая количество аргументов путем фиксации значений некоторых из них: для 
программы $p$, реализующей функцию $p'$ с $m+n$ аргументами и для заданных значений 
$a_1,\ldots,a_m$ для первых $m$ аргументов существует программа $g$ для специализированной 
$n$-местной функции, удовлетворяющая $\llbracket g\rrbracket(b_1,\ldots,b_n) = 
p'(a_1,\ldots,a_m, b_1,\ldots,b_n)$ для любых $b_i$.

Также существует вычислимая (примитивно рекурсивная при определённом выборе языка 
программирования) всюду определённая функция, --- собственно, $S^m_n$-функция, --- преобразующая 
программу $p$ в программу $g$.

То есть, для программы $p$ выполняется $\llbracket S^m_n(p, 
a_1,\ldots,a_m)\rrbracket(b_1,\ldots,b_n) = \llbracket p\rrbracket(a_1,\ldots,a_m, 
b_1,\ldots,b_n)$.

Далее пригодится частный случай $S^1_1$ с фиксацией всего одного из двух аргументов.

Нетрудно видеть, что $S^m_n$ теорема, по-существу, реализует частичные вычисления (специализацию 
программ) [4, 5], т.е. дает возможность выполнить часть вычислений, зависящих от фиксируемого 
аргумента(-ов), заранее, до выполнения программы (что может быть использовано, например, для 
оптимизации кода). Есть некоторое сходство между частичной специализацией и *каррингом* из 
функционального программирования.

Доказательство $S^m_n$ теоремы конструктивно и может быть основано на явном выписывании 
программы (или на явном построении машины Тьюринга), присваивающей определенные значения 
исключаемым аргументам и обеспечивающей запуск программы при поступлении недостающих данных 
(такого тривиального алгоритма недостаточно для написания оптимизирующего специализатора; но он 
может быть улучшен).

(Само доказательство здесь приводится не будет, а интересующимся рекомендуется обратиться к 
первоисточникам или более современным материалам по теории вычислимости.)

Стоит отметить, что вышеприведенные теоремы во многом схожи, и даже в некотором смысле 
<<взаимо-обратны>> -- теорема об универсальной функции преобразует <<статический>> параметр --- 
программу --- в <<динамический>> аргумент, который может затем принимать любое значение; 
$S^m_n$-теорема, напротив, преобразует динамический аргумент в статический, приписывая ему 
априори заданное значение.

Эта симметрия хорошо видна если выписать ключевые уравнения обоих теорем одно под другим 
(здесь, для краткости, используется $S^1_1$-функция):
{% tex block %}
\begin{align*}
\llbracket I\rrbracket(p, x, y) &= \llbracket p\rrbracket(x, y)\\
\llbracket S^1_1(p, x)\rrbracket(y) &= \llbracket p\rrbracket(x, y).
\end{align*}
{% endtex %}

В некотором смысле, они при этом всё-же различны -- кроме структурных различий формул, 
$S^m_n$-функцию можно считать примитивно рекурсивной (для её реализации не обязательно нужен 
универсальный язык программирования).

# Неподвижные точки вычислимых функций

Далее описывается теорема о существовании неподвижных точек вычислимых функций, известная также 
как вторая рекурсивная теорема Клини [14]; здесь приводится несколько упрощенная её версия, 
впрочем, полностью достаточная для решения поставленных задач.

**Вторая рекурсивная теорема Клини.**

Для любой вычислимой функции $f(\cdot, \cdot)$ существует программа $p$ (<<неподвижная точка>>), 
такая, что $$\forall z \ \llbracket p\rrbracket(z)=f(p, z).\eqno (1)$$

**Доказательство.**

Напишем программу $e$, такую, что $\llbracket e\rrbracket(x, y)=f(S^1_1(x, x), y)$. Тогда 
$p=S^1_1(e, e)$.

Действительно, если запустим $p$ для какого-нибудь аргумента $z$, то получим $\llbracket 
p\rrbracket(z)=\llbracket S^1_1(e, e)\rrbracket(z)$. По определению $S^1_1$-функции, $\llbracket 
S^1_1(e, e)\rrbracket(z)=\llbracket e\rrbracket(e, z)$. Теперь применим определение для $e$ и 
получим, что $\llbracket e\rrbracket(e, z)=f(S^1_1(e, e), z)=f(p, z)$. Понятно, что эта цепочка 
равенств по транзитивности приводит к $\llbracket p\rrbracket(z)=f(p, z)$. $\blacksquare$

В данном сообщении особый интерес представляет частный случай $f(x, y)=x$, порождающий квайны: 
легко видеть, что при этом $\llbracket p\rrbracket(z)=f(p, z)=p$, то есть программа $p$ при 
запуске печатает сама себя, как и положено квайну.

Иногда пригождается другая версия этой теоремы (при определенном выборе языка, строго 
говоря, не эквивалентная теореме Клини; см. [39]), предложенная в [19]:

**Теорема Роджерса.**

Для любой всюду определённой вычислимой функции $f(\cdot)$ существует неподвижная точка $p$, 
т.е. такая программа $p$, что $\forall z \llbracket p\rrbracket(z)=\llbracket 
f(p)\rrbracket(z)$.

**Доказательство.**

Определим функцию $h(e)$ так, что $$\llbracket h(e)\rrbracket = \big\llbracket\llbracket 
e\rrbracket(e)\big\rrbracket.\eqno (2)$$ Теперь напишем программу $e$, такую, что $\forall z$ 
выполняется $$\llbracket e\rrbracket(z) = f\big(h(z)\big).\eqno (3)$$ Утверждается, что $p=h(e)$ 
-- есть искомая неподвижная точка.

Подстановка (3) в правую часть (2) дает $\big\llbracket\llbracket e\rrbracket(e) 
\big\rrbracket=\llbracket f\big(h(e)\big) \rrbracket$ и $\llbracket 
h(e)\rrbracket=\llbracket f\big(h(e)\big)\rrbracket$. Последнее уравнение при обозначении 
$p=h(e)$ уже соответствует определению неподвижной точки из условия этой теоремы, т.е., 
$\llbracket p\rrbracket=\llbracket f(p)\rrbracket$. $\blacksquare$

N.B., во второй теореме Клини о рекурсии мы можем выбрать любую вычислимую функцию $f$, даже 
если она не определена для некоторых значений аргументов (т.е. если соответствующая этой функции 
программа зависает при таких входных данных); в теореме Роджерса мы можем выбрать только всюду 
определённую функцию $f$, иначе в выражении $\llbracket f(x)\rrbracket$ не было бы смысла при 
некоторых $x$.

Из теоремы Клини и теоремы об универсальной функции следует теорема Роджерса, а из теоремы 
Роджерса и $S^m_n$-теоремы -- теорема Клини. (Но есть нюансы [39].)

Для применения теоремы Роджерса к случаю с квайнами, удобно, следуя [2], ввести оператор 
$\operatorname{quote}$, для данного аргумента конструирующий программу, печатающую этот 
аргумент. Т.е. определение оператора $\operatorname{quote}$ выглядит как 
$\llbracket\operatorname{quote} z\rrbracket=z$ [и почти соответствует одноименному оператору из, 
e.g., lisp'а].

Квайны суть неподвижные точки этого оператора [в смысле формулировки теоремы Роджерса].

**Доказательство.**

Пусть $q$ -- неподвижная точка $\operatorname{quote}$, т.е. $\forall z$ выполняется 
$\llbracket\operatorname{quote} q\rrbracket(z) = \llbracket q\rrbracket(z).$ Подстановка 
определения $\operatorname{quote}$ в это уравнение дает $\llbracket\operatorname{quote} 
q\rrbracket(z)=q=\llbracket q\rrbracket(z)$. Но $q=\llbracket q\rrbracket(z)$ и есть определение 
квайна. $\blacksquare$

**Примечание.**

Вообще, в математике, неподвижной точкой функции $f(\cdot)$ обычно называют значение 
$p$, такое, что $f(p)=p$ (i.e., $f$ оставляет $p$ неизменным). Поэтому <<неподвижные точки>> из 
теорем 1 и 2 не совсем соответствуют такому общепринятому определению.

Тем не менее, термин *неподвижная точка* хорошо отражает суть этих теорем -- некоторое 
преобразование не меняет значение аргумента, т.е. оставляет его неподвижным (более того, из 
$f(p)=p$ следует $\llbracket f(p)\rrbracket=\llbracket p\rrbracket$, i.e. неподвижные точки по 
Роджерсу очень близки к обычному определению; обратное, впрочем, неверно: рассмотренные теоремы 
о неподвижной точке вовсе не гарантируют наличия обычной неподвижной точки $p$, такой, что 
$f(p)=p$).

Я лишь намереваюсь, в рамках этой серии сообщений, для удобства ввести обозначения для этих 
<<нестандартных>> неподвижных точек, а именно, пусть операторы $\operatorname{kfix} f$ и 
$\operatorname{rfix} f$ обозначают неподвижные точки [функции $f$] из теорем Клини и Роджерса, 
соответственно. В контексте, требующем работы с несколькими неподвижными точками, эти операторы 
будут обозначать множества неподвижных точек. Обозначение $\operatorname{fix} f$ будет 
использоваться для множества традиционных неподвижных точек, $\operatorname{fix} f=\{x\colon 
f(x)=x\}$. А так как, в общем случае, неподвижная точка не является единственной, запись типа 
$p=\operatorname{fix} f$ пусть означает $p\in\operatorname{fix} f$ (и аналогично для 
$\operatorname{kfix}$, $\operatorname{rfix}$).

Финальное замечание, полностью оправдывающее название <<неподвижная точка>> для операторов 
$\operatorname{kfix}$ и $\operatorname{rfix}$: введем оператор $\operatorname{fix}_R f=\{x\colon 
\big(f(x), x\big)\in R\}$, где $R$ -- некоторое двуместное отношение. Тогда 
$\operatorname{fix}\equiv\operatorname{fix}_=$. Другие типы неподвижных точек можно теперь тоже 
определять через $\operatorname{fix}_R$ при должном выборе отношения $R$. Например, пусть 
отношение $\leftrightsquigarrow$ сравнивает программы по их эффекту, т.е., 
$p\leftrightsquigarrow q \iff \llbracket p\rrbracket=\llbracket q\rrbracket$. Тогда 
$\operatorname{rfix} = \operatorname{fix}_\leftrightsquigarrow$. (N.B., как обычно, запись 
$p\leftrightsquigarrow q$ есть сокращение для $(p, q)\in\leftrightsquigarrow$).

# Главный эксперимент

В [42] приведен следующий эксперимент по квайногенерации на lisp (автор кода мне не известен):
```lisp
(define g (quote (lambda (x y) x))) ; g(x, y) = x

(define s11 (quote (lambda (f x) (list (quote lambda)
    (quote (y)) (list f x (quote y)))))) ; from s-m-n theorem

(define m (list (quote lambda) (quote (x y))
    (list g (list s11 (quote x) (quote x)) (quote y))))

(define quine (eval (list s11 m m)))

; tests
(eval (list quine nil))
(eval (list g quine nil))
```

(В [47] можно найти невероятную коллекцию аналогичных экспериментов со второй рекурсивный 
теоремой Клини, выполненных на языке scheme, диалекте lisp'а.)

Этот фрагмент кода просто воспроизводит доказательство второй рекурсивной теоремы Клини. 
Аналогичным образом я действовал и при повторении этого эксперимента на sed. Соответствующий код 
может быть найден в GitHub-репозитории [46]. Конкретно, в репозитории содержится ряд скриптов, 
`*.sed` и `*.sh`, назначение каждого из которых рассмотренно ниже.

Редактор sed направляет данные со стандартного ввода в основной буфер редактирования (т.н. *the 
pattern space*). И т.к. мне не известен способ передачи традиционных аргументов командной 
строки скрипту для этого редактора, то именно чтение со стандартного ввода было применено в 
качестве единственного механизма передачи аргументов. При этом, из-за необходимости передачи 
нескольких аргументов, понадобилось либо ввести разделитель/терминатор (e.g. нулевой байт), либо 
приписывать значение длины перед каждым аргументом. Как ни странно, изначально был выбран второй 
метод, в основном из-за отсутствия необходимости в экранировании разделителя.

Итак, далее приведен перечень скриптов с их кратким описанием:

- `construct-input.sh` принимает на вход список файлов со значениями аргументов и формирует 
   пакет аргументов из них, т.е. читает эти значения и посылает на стандартный вывод, снабдив 
   заголовками (длинами). Формат пакета данных с аргументами выглядит так:
   
   ```
   <длина аргумента 1>...<длина аргумента n><аргумент 1>...<аргумент n>
   ```
   
   Длина каждого аргумента представлена двоичным шестнадцатиразрядным числом (т.е. этот формат 
   не отличается универсальностью, но этого хватает для практического применения).
- Скрипт `s11.sed` [тривиально] реализует $S^1_1$-функцию. Этот сценарий принимает исходную 
   программу $p$ в первом аргументе и фиксируемый аргумент $x$ для неё -- во втором своем 
   аргументе. Результатом работы скрипта будет другая программа, полученная путем приписывания к 
   $p$ небольшого <<инъектора>> -- фрагмента кода, встраивающего ранее принятый аргумент $x$ (и 
   теперь являющийся частью инъектора) перед новым аргументом $y$ (который будет передан 
   формируемой программе при её запуске). После модификации пакета аргументов, инъектор передаёт 
   управление программе $p$ так, что она <<видит>> пару аргументов $x$ и $y$, несмотря на то, 
   что при запуске ей был передан единственный аргумент $y$.
   
   Небольшая техническая сложность заключается в необходимости экранирования специальных 
   символов в аргументе $x$ при формировании инъектора (с $x$, встроенным в него). Экранирование 
   производится в соответствии с синтаксисом регулярных выражений sed, путем добавления 
   символа`\` перед некоторыми символами, вроде того же `\` или перевода строки `\n`.
- `minifier.sed` используется для удаления ненужных символов (пустые строки, комментарии). При 
   генерации квайна этот скрипт применяется для *опционального* <<сжатия>> скриптов `s11.sed` и 
   `duplicate-first.sed`, что впоследствии уменьшает размер и увеличивает скорость работы 
   результирующего квайна.
- `is-quine.sh` -- простой shell-скрипт, проверяющий переданный ему в аргументах sed-скрипт и 
   определяющий, является ли он квайном.
- `generate.sh` производит <<минификацию>> скриптов `s11.sed` и `duplicate-first.sed`, после 
   чего запускает `generate-q.sh`, а после его завершения проверяет готовый продукт --- квайн в 
   файле `q.sed` --- с помощью скрипта `is-quine.sh`
- `duplicate-first.sed` принимает два аргумента $x$ и $y$ и заменяет второй первым, т.е., 
   игнорирует $y$ и формирует пакет из двух одинаковых аргументов $x$ и $x$.
- `generate-e.sh` конструирует программу $e$ из доказательства теоремы Клини. Для этого 
   [минифицированный, сжатый] код программы `duplicate-first.sed` добавляется в начало [тоже 
   сжатого] `s11.sed` и объединённый код сохраняется в `e.sed`. При запуске $e$, как и 
   требуется, будет выполняться $\llbracket e\rrbracket(m, x) = S^1_1(m, m)$, т.е. сначала 
   второй аргумент будет заменен первым (с помощью кода из `duplicate-first.sed`), затем 
   управление будет передано коду $S^1_1$-функции из `s11.sed`.
- `generate-q.sh` сначала запускает `generate-e.sh` для создания `e.sed`, потом запускает 
   `s11.sed` (или его сжатую версию, хотя здесь это не имеет значения) передав ему в качестве 
   обоих его аргументов содержимое только что сгенерированного `e.sed`. (N.B., `generate-e.sh` 
   использовал содержимое `s11.sed` для генерации `e.sed` на его основе; в данном же случае, 
   скрипту `generate-q.sh` не требуется доступ к тексту `s11.sed`, но лишь возможность его 
   выполнения; по той же причине здесь не используется `duplicate-first.sed`)
- `first-only.sed` из двух переданных ему аргументов возвращает только первый. Реализует 
   $\mathrm{K}$-комбинатор из комбинаторной логики и $\mathrm{SKI}$-исчисления. В 
   дистрибутив/репозиторий включен просто для демонстрации, хотя, в соответствии с 
   доказательством теоремы Клини, является реализацией функции $f(x, y)=x$, позже 
   использовавшейся для доказательства существования квайна.
- `concat.sed` возвращет объединённые значения обоих аргументов; никакие заголовки в результат 
   не включаются. На деле, `concat.sed` включен в репозиторий только для демонстрации -- скрипт 
   `generate-e.sh` не использует `concat.sed`, а производит объединение текстов просто 
   последовательным копированием оных в целевой файл.

(Заметьте, последние два скрипта, `first-only.sed` и `concat.sed` концептуально не являются 
лишними и они могли бы быть использованы, но по-факту, в ходе оптимизации, были заменены 
аналогичными средствами командной оболочки, -- для эффективности.)

Для генерации квайна достаточно запустить `./generate.sh`, в результате чего в том же каталоге 
[через некоторое время] должен появиться файл `q.sed`, являющийся искомым квайном на sed.

# Промежуточные итоги

Описание основного эксперимента завершено (и я рекомендую немного поизучать код скриптов из 
репозитория). Но о квайнах рассказать можно ещё многое. А некоторые вопросы остаются 
вовсе малоизученными, фактически, открытыми.

Несмотря на приведенные доказательста теорем о неподвижных точках (Клини и Роджерса), кому-то, 
может быть, хотелось бы глубже понять структуру этих и подобных им доказательств. Поэтому ниже я 
приведу некоторые дополнительные сведения с примерами. К концу сообщения я попробуя немного 
задеть некоторые из философских аспектов квайнов и теории вычислимости. И, пожалуй, завершу 
изложение попыткой сформулировать интересующие меня, но пока не имеющие официального ответа 
открытые вопросы.

Надеюсь, это не последнее сообщение этой серии. Поэтому, темы, не затронутые здесь, будут, по 
возможности, обсуждаться позже в других частях.

# Дополнительная теория

## Проблема остановки

Проблемой останова(-ки) называют задачу определения завершаемости произвольной программы по её 
коду. Известна теорема об алгоритмической неразрешимости такой задачи, т.е. о невозможности 
построения алгоритма, устанавливающего для произвольной программы конечность времени её 
выполнения [8].

**Доказательство 1.**

В пользу этого утверждения можно привести такие доводы. Введем функцию $h(p, x)$, определённую 
для всех $p$, которая в качестве своих аргументов принимает текст некоторой программы $p$ и 
входные данные $x$ этой программы, после чего возвращает 1 если эта программа завершается за 
конечное время, и 0 -- если программа <<зависает>>: $$h(p, x)=\begin{cases}1, & \llbracket 
p\rrbracket(x)\neq\bot\\0, & \llbracket p\rrbracket(x)=\bot.\end{cases}$$

Пусть $f(x, y)$ -- любая вычислимая (реализуемая в виде компьютерной программы) функция двух 
аргументов, способная обрабатывать тексты программ. Напишем программу $g$ так, чтобы 
выполнялось: $$\llbracket g\rrbracket(p)=\begin{cases}0, & f(p, p)=0\\\bot.\end{cases}$$

Т.е. $g$ передаёт свой аргумент функции $f$ и если та возвращает ноль, то ноль (или любое другое 
конечное значение) возвращает и $g$, но в противном случае $g$ возвращает неопределенное 
значение, а именно зависает, входя в бесконечный цикл.

Так как $f$ тоже реализуема в виде программы (т.е. вычислима), то получение значения $f(p, p)$ 
можно считать обычным вызовом подпрограммы. Все остальные действия (проверка на равенство нулю, 
возврат результата, условный переход, бесконечный цикл) тоже выполнимы на любом комппьютере.

Теперь мы можем передать программе $g$ её собственный текст; тогда, если $f(g, g)=0$, то и 
$\llbracket g\rrbracket(g)=0$. Другими словами, в этом случае $g$ возвращает результат и 
завершается, т.е. $h(g, g)=1$. Если же $f(g, g)=1$, то $\llbracket g\rrbracket(g)$ зависает и 
таким образом $h(g, g)=0$.

В любом случае, из этого получается, что $f(g, g)\neq h(g, g)$. Таким образом, функция $h$ не 
совпадает [хотя бы в одной точке] с вычислимой $f$. А из произвольности выбора функции $f$ 
немедленно вытекает, что функция $h$ не совпадает вообще ни с одной вычислимой функцией, т.е. 
$h$ невычислима (в смысле несуществования программы, вычисляющей значение этой функции для всех 
программ). $\blacksquare$

**Доказательство 2.**

Интересно, что можно воспользоваться теоремой Клини и попробовать доказать проблему останова 
методом <<от противного>>.

Допустим, определённая выше функция останова $h(x, y)$ -- вычислимая. Определим вычислимую 
функцию $$f(x, y)=\begin{cases}\bot, &h(x, y)=1\\1, &h(x, y)=0.\end{cases}$$ Вторая рекурсивная 
теорема говорит, что $\exists p\forall y\ \llbracket p\rrbracket(y)=f(p, y)$. Определение 
равенства вычислимых функций, определение $f$ и определение функции останова дают следующие 
цепочки логических эквавалентностей $$\begin{cases} \llbracket p\rrbracket(y)\neq\bot \iff f(p, 
y)\neq\bot \iff h(p, y)=0 \iff \llbracket p\rrbracket(y)=\bot\\\llbracket p\rrbracket(y)=\bot 
\iff f(p, y)=\bot \iff h(p, y)=1 \iff \llbracket p\rrbracket(y)\neq\bot,\end{cases}$$ Пришли к 
противоречию; значит, функция $h$ не является вычислимой. $\blacksquare$

## Диагонализация

Схема первого доказательства для проблемы останова фактически основана на процедуре 
диагонализации [6]. Второе доказательство, впрочем, тоже: ведь оно использует теорему Клини, 
доказательство которой также основано на диагонализации. Далее я попытаюсь пояснить суть этого 
процесса. Итак, если у нас есть некоторая бесконечная матрица $a_x^y$ (верхний индекс нумерует 
строки, нижний -- столбцы), то мы можем построить вектор-строку $b$, не совпадающий ни с одной 
из строк матрицы. Для этого достаточно лишь каким-то образом преобразовать элементы диагонали 
(отсюда название метода) матрицы $a$ так, чтобы для любого $z$ выполнялось $b_z\neq a_z^z$ 
(например, $b_z=1+a_z^z$).

Действительно, предположим, что $b$ равен одной из строк матрицы $a$. Это означает, что 
существует такой индекс $z$, что $b_i=a^z_i$ для всех $i$. Однако, по-построению $b$, при 
$i=z$ имеет место неравенство $b_z\neq a_z^z$; противоречие. Следовательно, мы действительно 
построили новый объект $b$, не входящий в матрицу $a$.

**Примечание.**

Название метода (диагонализация) несколько условно, т.к., по-видимому, достаточно чтобы в каждой 
строке был хотя-бы один преобразуемый элемент, совсем не обязательно лежащий на главной 
диагонали. [44] (Правда, нужно учитывать, что перестановкой строк можно вернуть преобразуемые 
элементы на диагональ матрицы; это замечание пока имеет интуитивный характер и детального 
анализа здесь не будет.)

Возможно, что пока применение этого трюка с конструированием патологической строки матрицы может 
показаться далёким от приведенных доказательств разбираемых здесь теорем (Клини, Роджерса и 
проблемы остановки); поэтому представляется нелишним небольшое продвижение ближе к историческим 
основам метода, и, я надеюсь, это сразу прояснит связь по крайней мере с проблемой останова. 
А вот теоремы о неподвижных точках потребуют большего внимания... Итак, сейчас копнём вглубь 
истории.

## Теорема Кантора

Изначально, диагональный метод был разработан и применен Кантором [7] для доказательства 
существования множеств, больших любого счетного бесконечного множества, или, точнее говоря, для 
доказательства несуществования сюръекции $\mathbb{N}\to\wp(\mathbb{N})$, где $\wp(\mathbb{N})$ 
-- булеан множества $\mathbb{N}$. Можно выразить теорему Кантора так: 
$\mathbb{N}\lneqq\wp(\mathbb{N})$. В более общем виде, теорема Кантора говорит о несуществовании 
сюръекции $X\to Y^X$, где $X$, $Y$ -- некоторые множества (причем $Y$ должно быть невырожденным, 
например в смысле существования беспорядка $Y\to Y$, т.е., перестановки без неподвижных точек), 
а $Y^X$ -- множество всех функций $X\to Y$ (структурно, обозначение $Y^X$ соответствует формуле 
$|Y|^{|X|}$ для подсчета количества таких функций).

Рассмотрим более детально пример с $\mathbb{N}<\wp(\mathbb{N})$.

Мы можем закодировать произвольное подмножество $N\subseteq\mathbb{N}$ двоичной маской, т.е. 
последовательностью $m_i$, такой, что $m_i=1$ если $i\in N$ и $m_i=0$ если $i\notin N$.

После этого мы сможем определить матрицу $a_j^i$ (бесконечных размеров), каждая строка $a^i$ 
которой будет содержать двоичную маску для каждого подмножества $\mathbb{N}$. Теперь мы применим 
к диагональным элементам $\{a_i^i\}_i$ матрицы операцию инвертирования $\alpha\colon 
x\mapsto x+1\pmod 2$ (т.е. $\alpha(0)=1$ и $\alpha(1)=0$), в результате чего получим новый 
бесконечный вектор-строку $b_k=\alpha(a_k^k)$, который не будет совпадать ни с одной из строк 
матрицы.

Т.е. мы получили совершенно новый объект, имеющий конкретное описание в виде двоичной 
последовательности, тоже могущей быть двоичной маской для некоторого подмножества $\mathbb{N}$, 
но не входящей в матрицу $a$. Этот пример показывает, что раз строки матрицы пронумерованы 
числами $\mathbb{N}$, а мы получили <<лишнюю>> двоичную маску, определяющую некое <<лишнее>> 
подмножество $\mathbb{N}$, то множество всех подмножеств $\mathbb{N}$, содержащее это лишнее 
подмножество и обозначаемое $\wp(\mathbb{N})$, строго больше самого $\mathbb{N}$; выражение 
<<строго больше>> означает, что в $\wp(\mathbb{N})$ есть лишние, дополнительные элементы и 
нельзя определить какую-нибудь функцию из $\mathbb{N}$ *на* $\wp(\mathbb{N})$, т.е. такую 
функцию, чтобы у каждого элемента $\wp(\mathbb{N})$ был прообраз.

Применительно же к проблеме останова, в качестве бесконечной матрицы используются значения $f(x, 
y)$, т.е. строки соответствуют функциям. Причем диагональные значения оборачиваются в функцию 
$\llbracket g\rrbracket$ так, чтобы функция останова $h$ [хотя бы на диагональных элементах 
матрицы] возвращала результат, отличный от результата применения $f$ к тем же аргументам.

## Теорема Ловера

Уильям Ловер предложил [43] обобщенную теорему из которой следуют многие другие результаты 
диагонализации, включая и проблему останова и теорему Гёделя о неполноте и некоторые другие. См. 
[44] для изложения тех же результатов на языке теории множеств (работа [43] сформулирована с 
существенным привлечением теории категорий).

## Связь диагонализации с теоремами о неподвижной точке

(Этот подраздел добавлен через месяцы после размещения в моем дневнике первой версии этого 
сообщения. Добавить новый подраздел, демонстрирующий роль диагонализации при поиске неподвижных 
точек, я решил после того как однажды прочитал своё же сообщение и не увидел чётких следов 
диагонального процесса в приведенных доказательствах теорем Клини и Роджерса, кроме характерного 
приема с самоприменением программ... Материал в основном написан по мотивам [56].)

В рассмотренных выше примерах применения диагонального процесса мы определяли множество всех 
объектов определённого типа, представляли их строками матрицы, а затем применяли некоторую 
операцию к диагональным элементам и т.о. конструировали новый объект, не могущий быть описанным 
ни одной строкой матрицы. Но при поиске неподвижной точки, как в теоремах Клини и Роджерса, 
требуется, наоборот, построить или найти объект с требуемыми свойствами в исходном наборе, а не 
доказать, что его там нет. Причем же тут диагонализация?

Все дело в том, что если нам удается построить новую последовательность $b$ (иногда называемую 
антидиагональю [ которую не следует путать с побочной диагональю матрицы]), путем применения 
некоего преобразования $\alpha$ к диагональным элементам матрицы $a$, то мы, как уже было 
сказано ранее, можем быть уверены, что среди строк матрицы $a$ объекта $b$ нет. Но если по 
какой-то причине <<антидиагональный>> объект $b$ построить не получается, то среди строк матрицы 
$a$ может оказаться её диагональ. Т.е. возможно существует индекс $z$, такой, что $a^z_i=a^i_i$.

Нас интересует случай замкнутости набора строк матрицы относительно действия $\alpha$: для любой 
строки $a^i$ существует строка $a^j$ равная образу $a^i$, т.е., $\forall k\ 
a_k^j=\alpha(a_k^i)$. Итак, если диагональ матрицы равна её строке $a^z$, то в силу замкнутости 
строк относительно $\alpha$, существует строка $a^w=\alpha(a^z)$, а так как $\forall i\ 
a_i^z=a^i_i$, то и образ диагонали под действием $\alpha$ тоже оказывается среди строк: $\forall 
i\ a_i^w=\alpha(a^i_i)$.

Но если результат преобразования диагонали равен одной из строк, то это означает, что на 
пересечении этой строки с главной диагональю матрицы есть элемент, переходящий в себя под 
действием преобразования $\alpha$. Другими словами, $\alpha(a_w^w)=a_w^w$, i.e., $a_w^w$ -- 
неподвижная точка $\alpha$.

Возможно в визуализации этой идеи поможет следующий рисунок (матрица $a$ схематично изображена в 
виде таблицы; вместо каких-либо конкретных значений её ячеек используется символ $\circ$):

{% tex block %}
{% raw %}
\begin{tikzpicture}
    \def\xwidth{.5cm} \def\xheight{.5cm}
    \def\lastcolumn{9} \def\lastrow{9}
    \tikzstyle{xarrow}=[->,line width=0.5mm]
    \foreach\x in {0,...,\lastcolumn}
        \foreach\y in {0,...,\lastrow}
        {
            \tikzstyle{xdraw}=[] \tikzstyle{xfill}=[]
            \tikzstyle{xnode}=[minimum width=\xwidth, minimum height=\xheight]
            \ifnum\x=\y \ifnum\x<\lastcolumn \tikzstyle{xdraw}=[draw,thick] \fi\fi
            \ifnum\y=3 \tikzstyle{xfill}=[fill=red!50!white] \fi
            \ifnum\y=7
                \ifnum\x=7
                    \tikzstyle{xfill}=[fill=green]
                \else
                    \tikzstyle{xfill}=[fill=red!50!white]
                \fi
            \fi
            \node[xfill,xdraw,xnode] at (\x*\xwidth,-\y*\xheight) {%
                \ifnum \y=\lastrow
                    \ifnum \x=\lastcolumn $\ddots$ \else $\vdots$ \fi
                \else
                    \ifnum \x=\lastcolumn $\cdots$ \else $\circ$ \fi
                \fi
            };
        }
    \node (a) at (6*\xwidth,-11*\xheight) {$a^w_w=\alpha(a^w_w)$};
    \node[minimum size=2mm] (b) at (7*\xwidth,-7*\xheight) {};
    \node[inner sep=0] (c) at (-1.5*\xwidth,1.5*\xheight) {$\triangle$};
    \node[minimum size=3mm] (d) at (0,0) {};
    \draw[xarrow] (a) to[bend left] (b);
    \draw[xarrow] (c) -- (d);
    \node (e) at (-\xwidth,-3*\xheight) {$z$};
    \node (f) at (-\xwidth,-7*\xheight) {$w$};
    \node (g) at (6*\xwidth,1.5*\xheight) {$a^4_5$};
    \node (h) at (5*\xwidth,-4*\xheight) {};
    \draw[xarrow] (-\xwidth,0) to[bend right] node[auto,swap] {$\operatorname{id}$} (e);
    \draw[xarrow] (e) to[bend right] node[auto,swap] {$\alpha$} (f);
    \draw[xarrow] (g) to[bend left] (h);
\end{tikzpicture}
{% endraw %}
{% endtex %}

Ну вот, связь диагонализации и неподвижных точек в общих чертах продемонстрирована. Осталось 
выяснить, что же может пойти не так при построении вектора $b$. Напомню, что в случае с теоремой 
Кантора и проблемой останова диагонализация проходила успешно... Разгадка здесь всего-лишь в 
том, что в случае с неподвижными точками мы не строим функцию $\alpha$ специально так, чтобы у 
неё не было неподвижных точек. И лишь предполагая, допуская их наличие, мы применяем 
диагональный процесс для конструирования такой неподвижной точки. Получив же конкретное решение, 
можно легко убедиться, что это действительно неподвижная точка; с тем же успехом, мы могли бы 
просто угадать вид решения, а потом убедиться в его правильности. Т.о., если отбросить вариант с 
угадыванием, то конструктивный характер диагональной схемы существенен для её логической основы: 
мы создаём объект с нужными свойствами и назад пути уже нет в силу непротиворечивости 
используемых формальных систем (ведь если выведено некоторое утверждение, вывести его отрицание 
в таких системах уже не получится). (Рекомендую также глянуть интересное обсуждение логической 
основы диагонализации в [57].)

Пример приведем для теоремы Роджерса, более удобной из-за одноместности фигурирующей в ней 
функции. Требуется решить уравнение $\llbracket p\rrbracket=\llbracket f(p)\rrbracket$ 
относительно $p$ для любой всюду определённой вычислимой $f$. В соответствии с вышеизложенной 
схемой доказательства диагонализацией, далее предстоит определить матрицу $a$ и преобразование 
$\alpha$ так, чтобы неподвижная точка функции $\alpha$ подходила бы в качестве решения к 
уравнению из теоремы Роджерса.

По техническим причинам, о которых ещё будет сказано позже, вместо функции $\alpha$ мы введем 
отношение $\equiv_\alpha$ (его конкретный вид будет определён ниже). Вместо 
$\theta=\alpha(\psi)$ будем писать $\theta\equiv_\alpha\psi$; в частности, если некоторая 
функция $\psi$ -- искомая неподвижная точка, то будет выполняться $\psi\equiv_\alpha\psi$. К 
строкам матрицы и вообще к последовательностям это отношение применяется поэлементно.

Пусть элементы матрицы равны $a^i_j=\big\llbracket\llbracket i\rrbracket(j)\big\rrbracket$. Т.е. 
строка с индексом $i$ соответствует вычислимой функции с номером $i$; номера столбцов 
соответствуют значениям аргументов. (Заметьте, что элементы матрицы $a$ равны не самим значениям 
$\llbracket i\rrbracket(j)$, а вычислимым функциям с номерами $\llbracket i\rrbracket(j)$.) Если 
$\llbracket i\rrbracket(j)=\bot$ для некоторых $i$ и $j$, то считается, что элемент $a^i_j$ 
содержит нигде не определённую функцию: $\forall x\ a^i_j(x)=\bot$. Диагональ $\{a^i_i\}_i$ 
обозначим $\triangle$ и будем считать $\triangle_i=a^i_i$.

Если некоторый гипотетический объект $d$, для которого справедливо $\triangle\equiv_\alpha d$ не 
является <<патологическим>>, т.е. гарантированно отсутствующим среди строк матрицы, то диагональ 
может оказаться равной одной из строк.

Мы можем определить функцию $h(e)$, конструирующую программу, которая принимая аргумент $x$, 
применяет к нему диагональный элемент матрицы, находящийся на пересечении строки $e$ и столбца 
$e$. А именно, выполняется $$\llbracket h(e)\rrbracket=a^e_e\eqno (*).$$ Важно, что для 
вычисления $h(e)$ тоже можно написать программу $z$, т.е. $h(e)$ -- вычислимая функция. Это 
означает, что в матрице $a$ существует строка $a^z$ равная $\triangle$; действительно, из того, 
что $z$ является программой для $h$, а также из определения элементов $a^i_j$ и из $(*)$ следует 
$\forall i\ a^z_i=\big\llbracket \llbracket z\rrbracket(i)\big\rrbracket=\llbracket 
h(i)\rrbracket=a^i_i$. Если набор строк замкнут относительно $\equiv_\alpha$, то существует 
строка $a^w\equiv_\alpha a^z$; и именно её пересечение с $\triangle$ дает неподвижную точку: 
$a_w^w\equiv_\alpha a_w^w$.

Чтобы последнее уравнение выглядело как уравнение из теоремы Роджерса, определим отношение 
 $\equiv_\alpha$ так, что для функций $\theta$ и $\psi$ выполняется 
$\theta\equiv_\alpha\psi\iff\exists e\ \theta=\llbracket e\rrbracket \land \psi=\llbracket 
f(e)\rrbracket$. Попробуем показать, что $\forall k \exists r\forall i\ a^k_i\equiv_\alpha 
a^r_i$. Пусть $t$ -- такая последовательность, что $a^k\equiv_\alpha t$. Из определений 
элементов матрицы $a$ и отношения $\equiv_\alpha$ следует $a^k_i = \big\llbracket\llbracket 
k\rrbracket(i)\big\rrbracket$ и $t= \big\llbracket f\big(\llbracket 
k\rrbracket(i)\big)\big\rrbracket$. В силу вычислимости $f$, композиция $f\circ\llbracket 
k\rrbracket$ тоже вычислима и имеет некоторый индекс $r$, т.е., $t=\big\llbracket \llbracket 
r\rrbracket(i)\big\rrbracket$. В соответствии с определением элементов матрицы $a$, это 
выражение означает, что $t$ равна строке с индексом $r$. Т.о., мы только что показали, что набор 
строк замкнут относительно $\equiv_\alpha$.

Выше было установлено, что $\exists w\forall i\ a^z_i\equiv_\alpha a^w_i$. Левую часть перепишем 
с помощью $(*)$, учитывая равенство $a^z=\triangle$, а правую -- с помощью определения элементов 
матрицы $a$. Это даёт $\llbracket h(i)\rrbracket \equiv_\alpha \big\llbracket\llbracket 
w\rrbracket(i)\big\rrbracket$. Из определения отношения $\equiv_\alpha$ следует, что 
$\big\llbracket\llbracket w\rrbracket(i)\big\rrbracket=\llbracket f\big(h(i)\big)\rrbracket$. 
Это уравнение говорит, что $w$ -- один из возможных текстов программ, вычисляющих композицию 
функций $f\circ h$; кроме того, то же самое уравнение вместе с $(*)$ в случае с $i=w$ немедленно 
даёт $\llbracket h(w)\rrbracket=\llbracket f\big(h(w)\big)\rrbracket$. Таким образом, $h(w)$, 
где $w$ является программой для вычисления композиции $f\circ h$, -- искомая неподвижная точка 
из теоремы Роджерса, т.е., $h(w)\in\operatorname{rfix} f, \llbracket w\rrbracket=f\circ h, 
\llbracket h(e)\rrbracket=\big\llbracket\llbracket e\rrbracket(e) \big\rrbracket$.

Да, это построение выглядит более громоздким и запутанным чем изначально приведенное почти 
однострочное доказательство теоремы Роджерса, но оно, я надеюсь, позволяет более глубоко увидеть 
связь диагонального процесса с теоремами о неподвижных точках.

**Примечание.**

Ранее я говорил, что лучше использовать отношение $\equiv_\alpha$ вместо функции $\alpha$. Чтобы 
неподвижная точка $p$ функции $\alpha$ удовлетворяла уравнению $\llbracket 
p\rrbracket=\llbracket f(p)\rrbracket$, можно было бы определить $\alpha$ как $\alpha(\llbracket 
e\rrbracket)=\llbracket f(e)\rrbracket$. В принципе, та же схема доказательства работала бы и в 
этом случае: сначала мы бы выяснили, что строки замкнуты относительно $\alpha$, затем 
преобразовали бы строку $a^z$, равную диагонали $\triangle$, и получили бы новую строку 
$a^w=\alpha(a^z)$; завершилось бы такое доказательство проверкой, что элемент $a^w_w$, 
находящийся на пересечении $a^w$ и $\triangle$, удовлетворяет уравнению $a^w_w=\alpha(a^w_w)$.

Пусть некоторый элемент в $\triangle$ равен $\llbracket p\rrbracket$ для некоторого $p$. Тогда 
соответствующий элемент в $a^z$ равен $\llbracket q\rrbracket$ и равенство последовательностей 
$a^z=\triangle$ означает, что $\llbracket p\rrbracket=\llbracket q\rrbracket$. В строке $a^w$ 
элементу $\llbracket q\rrbracket$ из строки $a^z$ соответствует элемент $\alpha(\llbracket 
q\rrbracket)=\llbracket f(q)\rrbracket$. Проблема в том, что исходный элемент $\llbracket 
p\rrbracket$ из $\triangle$, под действием преобразования $\alpha$ должен перейти в $\llbracket 
f(p)\rrbracket$ и мы вынуждены потребовать, чтобы этот результат совпадал с $\llbracket 
f(q)\rrbracket$, ведь иначе нельзя будет говорить о $\llbracket p\rrbracket=\alpha(\llbracket 
p\rrbracket)$ если $\llbracket p\rrbracket$ будет желаемым элементом на пересечении $a^w$ и 
$\triangle$.

Другими словами, из равенства $a^z=\triangle$ должно следовать $a^w = \alpha(a^z) = 
\alpha(\triangle)$, а для этого требуется экстенсиональность функции $f$ -- должно выполняться 
$\llbracket p\rrbracket=\llbracket q\rrbracket\Rightarrow \llbracket f(p)\rrbracket=\llbracket 
f(q)\rrbracket$, i.e., одинаково ведущие себя программы, должны преобразовываться функцией $f$ 
снова в одинаково себя ведущие, однако не всякая вычислимая функция обладает такой формой 
монотонности. Трюк с заменой преобразования $\alpha$ (вместе с обычным сравнением функций) 
отношением $\equiv_\alpha$, позволяет обойти это ограничение и расширить класс пригодных функций 
до всех вычислимых всюду определённых.

### Версия <<от противного>>.

Рассуждения по схеме <<а вдруг>>, могут показаться не всегда удовлетворительными. Можно ли 
вместо попытки сконструировать желаемый объект --- неподвижную точку --- вопреки диагонализации 
(призванной доказать невозможность подобного мероприятия) попробовать облачить вышеизложенное в 
привычную схему доказательства от противного? Такое доказательство выглядело бы более привычно и 
ощущалось бы более весомым (ведь доказательство от противного основано на надёжном процессе 
поиска ошибки в цепочке умозаключений, приведших к абсурду; такой поиск призван, в итоге, 
локализовать ошибку, загнав её в единственный туманный уголок доказательства, а именно, в самое 
его начальное предположение, после чего способ исправления ошибки --- отрицанием предположения 
--- немедленно следует из закона исключённого третьего, и, таким образом любые претензии к 
качеству такого доказательства сводятся к вере в этот закон). Оказывается, что, да, 
доказательство, одновременно явно использующее диагонализацию и показывающее наличие неподвижной 
точки методом от противного, существует, и, в общем-то, широкоизвестно.

Итак. Определим бинарное отношение $\equiv$ так, что $\theta\equiv \psi\iff \llbracket 
\theta\rrbracket=\llbracket \psi\rrbracket$.

**Теорема (переформулировка теоремы Роджерса).**

Если $f$ -- всюду определённая вычислимая функция, то $\exists n\ n\equiv f(n)$.

**Доказательство теоремы Роджерса методом от противного.**

(N.B., Акцент в этой версии доказательства сделан на диагонализации, пусть и в ущерб 
конструктивности, --- здесь я не буду выводить явный вид неподвижной точки, хотя при желании 
его можно извлечь и из такой урезанной версии.)

Основное предположение: $\nexists n\ n\equiv f(n)$.

**Лемма 1 (без доказательства).** Для любой вычислимой функции $f$ существует вычислимая всюду 
определённая $g$ (т.н., $\equiv$-продолжение функции $f$), такая, что $\forall x\ 
f(x)\neq\bot\Rightarrow g(x)\equiv f(x)$.

Определим вычислимую всюду определённую функцию $h$, такую, что $h(x)=\llbracket 
x\rrbracket(x)=\varphi(x, x)$.

**Утверждение 1.** Не существует вычислимой функции $g$, такой, что $\forall x\ g(x)\neq h(x)$ 
(иначе это бы противоречило определению универсальной функции $\varphi$).

(N.B., конкретный вид $h$ на самом деле не важен, --- требуется лишь справедливость утверждения 
1, --- но здесь мы всё-таки зафиксируем такое <<диагональное>> выражение, и даже воспользуемся 
им в конце этого подраздела для лучшей визуализации процесса.)

По лемме 1, $\exists g \forall x\ g(x)\equiv h(x)$, т.е., $g(x)\equiv h(x)$. Определим функцию 
$t(x)=f\big(g(x)\big)$. Т.к. $f$ и $g$ и их композиция $t=f\circ g$ -- вычислима. Допустим, 
$\exists x\ t(x)=h(x)$. Это вместе с $g(x)\equiv h(x)$ и с определением отношения $\equiv$ ведет 
к $\llbracet g(x)\rrbracket=\llbracket h(x)\rrbracket=\llbracket t(x)\rrbracket$, из чего 
следует $t(x)\equiv g(x)$. Но $t=f\circ g$, откуда $g(x)\equiv f(g(x))$, однако по основному 
предположению, $\nexists n\ n\equiv f(n)$ ($g(x)$ выглядит как неподвижная точка, но мы 
предполагаем, что их не существует). Противоречие, значит, $t$ отличается всюду от $h$. Но это 
противоречит уже утверждению 1. Следовательно, основное предположение неверно и мы 
должны его исправить, заменив на $\exists n\ n\equiv f(n)$. $\blacksquare$

Обратите внимание, здесь мы имеем дело с матрицей $a^i_j=\varphi(i, j)$ в которой строки, как и 
прежде, соответствуют вычислимым функциям, а столбцы -- их аргументам (изменились только сами 
элементы матрицы). Функция $h(x)=\varphi(x, x)$ порождена диагональю $\triangle=\{a^i_i\}$. 
Лемма 1 говорит, что в матрице $a$ присутствует строка $a^z\equiv\triangle$ (отношение $\equiv$ 
применено поэлементно). Мы используем эту строку для конструирования кандидата в антидиагональ, 
а именно мы действуем на $a^z$ данной вычислимой функцией $f$, но т.к. строка $a^z$ 
соответствует функции $g$, а композиция $f\circ g$ вычислима, то среди строк должна найтись 
строка $a^w$ (пересекающая диагональ в некоторой точке).

Откуда же тогда берутся подозрения в антидиагональности $f\circ g$, т.е. в том, что $\forall x\ 
f\big(g(x)\big)\neq h(x)$? Мы знаем, что $g\equiv h$ (так мы строили строку $a^z$). Теперь если 
для какого-то $x$ верно $f\big(g(x)\big)=h(x)$, то в строке $a^z$ найдётся элемент $a^z_x\equiv 
h(x)$, но по определению элементов матрицы $a$, $a^z_x=g(x)$, откуда и вытекает выражение 
$g(x)\equiv f\big(g(x)\big)$, противоречащее основному предположению [о несуществовании 
неподвижной точки $n\equiv f(n)$], а значит опровергающее, методом от противного, наше 
предположение о том, что $f\circ g$ совпадает с $h$ в точке $x$.

На данный момент мы имеем уже два утверждения: одно говорит о том, что антидиагональ на самом 
деле равна строке $a^w$ и пересекается с диагональю в некоторой точке, а второе утверждение 
говорит, что антидиагональ действительно нигде не совпадает с диагональю. Эти утверждения 
противоречат друг другу, что абсурдно, и, опять методом от противного, приводит к утверждению, 
прямо противоположному основному предположению об отсутствии неподвижных точек у данной функции 
$f$.

Я специально воспроизвел последнее доказательство от противного в уже знакомых терминах матриц, 
диагоналей, строк, антидиагоналей, и т.д., чтобы придать максимальную наглядность процессу и 
окончательно удалить мистический налёт с диагонального доказательства теоремы о рекурсии.

# Немного о пределах познаваемости

Проблема останова разрешима для многих систем, например, для конечных автоматов, 
коими, кстати говоря, и являются реальные компьютеры. Правда, в силу огромного количества 
состояний таких автоматов, они, с практической точки зрения, хорошо моделируются машиной 
Тьюринга (или эквивалентными моделями, типа лямбда-исчисления). Поэтому, многие теоретические 
результаты, вытекающие из проблемы останова или доказываемые редукцией к ней, по прежнему 
применимы в обычном программировании.

Также проблема останова может быть вполне разрешимой для определенных частных случаев. Например, 
в теории, антивирусы невозможны (это доказывается редукцией к проблеме остановки), но они 
всё-таки <s>вертятся</s> существуют как программные продукты (в том числе, благодаря 
<<маркетингу>>, наверное). В теории, невозможно написать программу-детектор, безошибочно 
определяющую, что другая программа печатает на экране, например, слово <<привет>> [28, 29]. Но 
ведь многие бы без труда написали такой детектор. Даже сами доказательства теорем, в силу 
соответствия Карри-Ховарда, вообще говоря, требуют решения проблемы остановки. Но ведь 
математики как-то доказывают теоремы! Иногда при помощи компьютера (и автоматизированно и даже 
автоматически).

Эти исключения не являются ошибками или фактами, опровергающими упомянутые контринтуитивные 
утверждения (содержащие квантор всеобщности). А положительные результаты имеют вполне конкретное 
применение. Компиляторы, интерпретаторы, квайны и многие другие интересные артефакты теории 
вычислимости существуют не только теоретически, но и имеют осязаемые реализации в виде реальных 
кусков кода и даже устройств (e.g. те же компьютеры). А теорема Гёделя о неполноте говорит, что 
некоторые теоремы просто не могут быть доказаны, -- не стоит даже и пытаться.

Наконец, диагонализация внесла некоторый вклад и в более абстрактные области философии. 
Например, применением диагонального процесса к демону Лапласа --- <<древнему>> суперкомпьютеру, 
имеющему неограниченный доступ к любой информации обо всех частицах вселенной --- была 
установлена <<монотеистическая>> теорема о невозможности существования более чем одного демона 
Лапласа [27].

В следующих сообщениях этой серии я напишу о некоторых из этих [как классических, так и 
относительно новых] результатов подробнее.

# Другие подходы и <<слегка открытые>> вопросы

В этом разделе обсуждаются достаточно простые, но до сих пор представляющие некоторый 
исследовательский интерес альтернативные подходы к конструированию квайнов. Некоторые из 
рассмотренных здесь вопросов могут быть тривиальными и, возможно, представляющими сложность лишь 
для меня; другие -- могут оказаться объективно стоящими дальнейшей проработки.

Более подробно все эти воросы будет или не будут освещены в следующем(-их) сообщении(-ях) этой 
серии.

## <<Креацианизм>> vs. <<абиогенез>>

Я условно назвал совокупность методов (как ручных, так и автоматических), применяемых для 
конструирования квайнов и основанных на существенном привнесении специально подготовленной 
внешней информации/знаний в этот процесс [квайнологическим] <<креацианизмом>>. Традиционное 
написание квайна вручную, а также его конструирования на основе второй рекурсивной теоремы Клини 
-- суть примеры креацианисткого подхода в квайнологии. В них требуется существенный контроль со 
стороны программиста.

В подразделах же, приведенных ниже, акцент сделан на автоматическом итеративном конструировании 
квайнов (если оно возможно). <<Абиогенетическое>>, самостоятельное <<зарождение>> квайнов 
потенциально могло бы представлять некоторую ценность в ряде областей. Так, например, 
квайнологический абиогенез был бы интересен в таком разделе информационной безопасности как 
компьютерная вирусология; он был бы применим в автономных системах (e.g., самомодифицирующееся 
ПО каких-нибудь марсоходов) и, возможно, интересен экзобиологам (в том смысле, что квайны, 
будучи <<дистиллированной>> моделью жизни, подошли бы для изучения тварей с *terra incognita*, 
-- будь-то океанские впадины, астероиды, космическая пыль/мусор, или любые другие субстраты).

## Кимианские квайны и итеративное вычисление неподвижной точки

Хофштадтер в [26] не только ввел термин <<квайн>>, но и описал там же ещё одну разновидность 
самореплицирующегося кода -- кимианские квайны, названные в честь Скотта Кима (Scott Kim), 
подсказавшего эту идею Хофштадтеру.

Кимианский квайн представляет собой текст, который будучи поданым на вход 
компилятора/интерпретатора, не распознается как корректный исходный текст, а приводит к выводу 
сообщения об ошибке [31]. Причём такое сообщение побуквенно совпадает с самим кимианским 
квайном. Т.е. при попытке запуска или компиляции, подобный код всё-таки воспроизводит себя, как 
и положено квайну.

Если обозначить среду исполнения для кимианского квайна (e.g., компилятор, интерпретатор или 
командную оболочку) как функцию $F(x)$, принимающую и возвращающую текстовую строку, то 
некоторый кимианский квайн $q$ будет неподвижной точкой этой функции: $F(q)=q$.

Интересно, что в данном случае $q$ может быть вычислен итерированием функции $F$ начиная с 
подходящего (иногда пустого) начального приближения. Т.е. алгоритм конструирования 
кимианского квайна должен будет вычислить $q=\lim_{k\to\infty}F^k(\varepsilon)$, где 
$F^k(x)=F\big(F^{k-1}(x)\big)$, $F^0(x)=x$ для некоторого начального значения $\varepsilon$.

Следует заметить, что такая функция $F(x)$ определена для всех $x$ (и к тому же всегда 
завершается, если речь идет о компиляторе без поддержки вычислительно-универсальных 
металингвистических средств, --- например, подобных C++ шаблонам, --- могущих приводить к 
<<зависанию>> компилятора).

В минирепозитории (gist) [33] можно найти простую реализацию подобного метода итеративного 
конструирования кимианского квайна, выполненную на языке командной оболочки bash. Скрипт 
принимает в качестве аргумента путь до исполняемого файла интерпретатора или компилятора, 
запускает его и передает ему имя файла, хранящего начальное приближение. Результат из потоков 
вывода сохраняется в этот же файл если этот результат отличается от содержимого файла, после 
чего процесс повторяется. И так до стабилизации процесса, т.е. пока данный интерпретатор не 
будет выдавать тот же текст, который он получил на вход.

Эксперименты показывают, что таким способом неподвижная точки находится не всегда. И это не 
удивительно. Теорема о неподвижной точке может быть переформулирована в форме утверждения о том, 
что алгоритм преобразования программного кода не может всегда возвращать программу, отличную от 
данной. И если неподвижная точка существует, то итерирование применения этого алгоритма *может* 
породить последовательность программ, сходящуюся к неподвижной точке. Но последовательность 
может сойтись и к какому-нибудь циклу. Т.е. даже если $\exists x\colon F(x)=x$, то возможно 
существует последовательность $x_0, \ldots, x_n$ такая, что $F(x_i)=x_{i+1}$ и $F(x_n)=x_0$. 
Причем, возможно, что $\exists i, k\colon F^k(\varepsilon)=x_i$.

Обсуждаемый скрипт [33] имеют рудиментарную поддержку определения таких циклов, но для меня 
остается открытым вопрос о возможности автоматического <<преобразования>> такого цикла в 
настоящую неподвижную точку (формально, в цикл из одного элемента).

(Несмотря на наблюдаемую эмпирическую сходимость итераций к неподвижной точке или к циклу, мне 
неизвестны какие-либо особые свойства функции $F$, гарантирующие стабилизацию процесса после 
конечного количества шагов.)

## Другие конструктивные теоремы о неподвижной точке

Пожалуй, это самый спекулятивный и неформальный подраздел этого сообщения. Здесь перечисляются 
некоторые известные теоремы о неподвижных точках, которые, возможно, могли бы быть применены для 
конструирования квайнов. Сама эта возможность находится под вопросом, но эти теоремы всё-же 
заслуживают упоминания в таком контексте.

### Первая рекурсивная теорема Клини

(Этот раздел написан по мотивам соответствующего материала из [50].)

Для функций $f_0\colon D_0\to R_0$ и $f_1\colon D_1\to R_1$, таких, что $D_0\subseteq D_1$, 
$R_0\subseteq R_1$ и $\forall x\in D_0\ f_0(x)=f_1(x)$ введем обозначение $f_0\sqsubseteq f_1$, 
читающееся как <<$f_1$ продолжает $f_0$>>. (Другими словами, выполняется импликация 
$f_0(x)\neq\bot\Rightarrow f_1(x)=f_0(x)$.)

Функция называется конечной если она имеет конечную область определения. *Конечной частью* 
функции $f$ назовём конечную функцию $\theta\sqsubseteq f$. Сопоставим функции $\theta$ 
натуральное число $g(\theta)$.

Подразумевается, что существует алгоритм, который по числам $z$ и $x$ вычисляет $\theta(x)$ если 
существует $\theta$, такая, что $z=g(\theta)$ и $\theta$ определена в точке $x$.

Оператор $F$ называется рекурсивным оператором если существует вычислимая функция $\phi(z, x)$, 
такая, что $\forall f, x, y\ F(f)(x)=y$ тогда и только тогда, когда существует конечная 
$\theta\sqsubseteq f$, такая, что $\phi\big(g(\theta), x\big)=y$.

Оператор $F$ непрерывен если $\forall f, x, y\ F(f)(x)=y$ тогда и только тогда, когда существует 
конечная $\theta\sqsubseteq f$, такая, что $F(\theta)(x)=y$.

Оператор $F$ называют монотонным, если $\forall f,g\ f\sqsubseteq g\Rightarrow F(f)\sqsubseteq 
F(g)$.

**Утверждение (без доказательства).**

Рекурсивные операторы непрерывны и монотонны.

**Теорема (без доказательства).**

Для любого рекурсивного оператора $F$ существует неподвижная точка $f$, т.е. $F(f)=f$. Причём 
$f$ -- наименьшая из неподвижных точек, в том смысле, что если для какой-нибудь другой функции 
$g$ выполняется $F(g)=g$, то $f\sqsubseteq g$. (Всюду определенная функция $f$ автоматически 
будет единственной неподвижной точкой.)

Для демонстрации связи с квайнами в [50] (и это практически единственная обнаруженная мной в 
литературе зацепка, связывающая первую рекурсивную теорему с квайнами) по-сути предлагается 
попробовать в качестве рекурсивного оператора взять оператор, аналогичный оператору 
$\operatorname{quote}$, определенному в разделе о теореме Роджерса (см. выше). Оператор 
$\operatorname{quote}$ преобразует программу $p$ в программу, печатающую текст $p$, а по только 
что изложенной первой рекурсивной теореме Клини, рекурсивный оператор (с семантикой оператора 
$\operatorname{quote}$) должен иметь неподвижную точку $f$ и если из этого следует, что и сам 
оператор $\operatorname{quote}$ имеет неподвижную точку $q$, такую, что $\operatorname{quote} 
q=q$, то, коль скоро программа $q$ равна программе, печатающей себя, $q$ есть квайн.

Здесь уместно прокомментировать согласованность этого вывода с данным выше определением 
рекурсивного оператора, ведь $\operatorname{quote}$ действует не на множестве вычислимых 
функций, а на множестве исходных текстов программ. Идея состоит в том, что оператор 
$\operatorname{quote}$, преобразуя некоторую программу $p_0$ в программу $p_1$, порождает 
рекурсивный оператор $\Phi$, преобразующий функцию $f_0=\llbracket p_0\rrbracket$ в функцию 
$f_1=\llbracket p_1\rrbracket$. Обозначим $\varphi(p)\equiv\llbracket p\rrbracket$, тогда 
вышеописанную идею можно проиллюстрировать следующей диаграммой:
{% tex block %}
{% raw %}
\begin{tikzpicture}[xscale=1.5]
\path node (m00) at (0,0) {$p_0$}
    node (m01) at (0,1) {$f_0$}
    node (m10) at (1,0) {$p_1$}
    node (m11) at (1,1) {$f_1$};
\draw[|->] (m00) -- node[left]{$\varphi$} (m01);
\draw[|->] (m10) -- node[right]{$\varphi$} (m11);
\draw[|->] (m00) -- node[below]{$\operatorname{quote}$} (m10);
\draw[|->] (m01) -- node[above]{$\Phi$} (m11);
\end{tikzpicture}
{% endraw %}
{% endtex %}

К оператору $\Phi$ напрямую применима первая рекурсивная теорема, т.е. существует $f$, такая, 
что $f=\Phi(f)$. Из этого следует, что существуют программы $q_0$ и $q_1$, причем 
$$q_1=\operatorname{quote} q_0.\eqno (4)$$ Т.к., $f=\llbracket q_0\rrbracket$ и 
$f=\llbracket q_1\rrbracket$, то $$\llbracket q_0\rrbracket=\llbracket q_1\rrbracket.\eqno 
(5)$$ Подставляя (4) в (5) и применяя определение оператора $\operatorname{quote}$ получаем 
$\forall z\ \llbracket q_0\rrbracket(z) = \llbracket\operatorname{quote} q_0\rrbracket(z) = 
q_0$, т.е. $q_0$ удовлетворяет <<уравнению квайна>> $\llbracket q_0\rrbracket(z)=q_0$ и, 
соответственно, является квайном.

(Для меня остается открытым вопрос о возможности применения первой рекурсивной теоремы для 
автоматического конструирования квайнов, как в случае со второй рекурсивной теоремой.)

### Теорема Клини о неподвижной точке [из теории решёток]

Произвольное отображение $F\colon M\to M$, непрерывное по Скотту и определенное на полном 
частично упорядоченном множестве $M$ с отношением порядка $\sqsubseteq$ имеет наименьшую 
неподвижную точку.

Непрерывность по Скотту означает существование $\sup F(S)$ и выполнение  $F(\sup S)=\sup F(S)$ 
для всякого направленного подмножества $S\subseteq M$.

### Теорема Кнастера-Тарского

В [37] приведена теорема о существовании неподвижных точек монотонных отображений на полной 
решетке. Пусть $F\colon L\to L$ -- монотонное отображение на полной решетке $L$ с отношением 
частичного порядка $\sqsubseteq$. Т.е. $\forall X, Y\in L, X\sqsubseteq Y\Rightarrow 
F(X)\sqsubseteq F(Y)$. Теорема Тарского утверждает, что $\operatorname{fix} F$, i.e. множество 
неподвижных точек отображения $F$, само является непустой полной решеткой.

В [38] доказана конструктивная версия этой теоремы. До этой работы, неподвижные точки монотонных 
отображений уже конструировали как $\sup F^i(\bot)$, где $i\in\mathbb{N}$, а $\bot=\inf L$. Но 
это требовало от $F$ непрерывности по Скотту. В [38] же доказывается теорема, которая не требует 
от $F$ этого свойства и утверждая, что $\operatorname{fix} F$ является полной решеткой 
относительно $\sqsubseteq$, предлагает, среди прочего, рецепт вычисления неподвижной точки в 
виде $\inf\operatorname{fix} F=\lim F^k(\bot)$.

Здесь $\lim F^k(\bot)$ определяется как предел стационарной последовательности 
$X^\delta=F(X^{\delta-1})$ при $X^0=\bot$. Считается, что $X^\delta=\sup_{\alpha<\delta} 
X^\alpha$ для предельного ординала $\delta$. Под стационарностью понимается, что начиная с 
некоторго индекса, элементы последовательности имеют одно и то же значение. Для корректного 
погружения в использованные в [38] трансфинитные определения необходимо чтение оригинальной 
статьи.

(Эти результаты обобщаются на случай полных частично упорядоченных множеств, только 
направленные, а не произвольные подмножества которых обязаны иметь супремум.)

## Комбинатор неподвижной точки в лямбда-исчислении

В $\lambda$-исчислении [34] для реализации рекурсии используются комбинаторы неподвижной точки, 
в основном $\mathrm{Y}$-комбинатор. Этот комбинатор определяется уравнением $\mathrm{Y} f\equiv 
f(\mathrm{Y} f)$ и в соответствии с этим определением вычисляет неподвижную точку функции $f$, 
т.е. такое выражение $x$, что $f x=x$.

Если конкретная реализация $\lambda$-исчисления поддерживает рекурсивные определения именованных 
символов, то вышеприведенного определения достаточно для работы с $\mathrm{Y}$-комбинатором 
(могут возразить, что в таком случае он не особо-то и нужен; однако, здесь $Y$-комбинатор может 
служить полезной обёрткой для некоторых функций, позволяющей, к примеру, добавить временное 
хранение промежуточных результатов с целью исключения их повторного вычисления, --- т.е., 
кэширование, --- и, соответственно, получить ускорение в духе динамического программирования).

В чистом же $\lambda$-исчислении требуется определить $\mathrm{Y}$-комбинатор в явном виде, 
например как $\mathrm{Y}\equiv \lambda f.\big(\lambda x. f (x x)\big) \big(\lambda x. f (x 
x)\big)$ (известный как комбинатор Карри или парадоксальный комбинатор) или, в случае 
использования императивного языка, задействовать [энергичный] комбинатор Тьюринга $\Theta_v=a 
a$, где $a\equiv\lambda x.\lambda y.y(\lambda z. x x y z)$.

**Теорема о неподвижной точке.**

Несмотря на неочевидность этого утверждения, в нетипизированном $\lambda$-исчислении любое 
выражение имеет неподвижную точку (хотя бы одну).

**Доказательство.**

Пусть $A\equiv\lambda x.\lambda y. y (x x y)$. Комбинатор Тьюринга есть $\mathrm{\Theta}\equiv A 
A$. Утверждается, что для любого $\lambda$-выражения $F$, выражение $N=\mathrm{\Theta} F$ есть 
его неподвижная точка. Чтобы увидеть это, запишем следующую цепочку уравнений:

{% tex block %}
\begin{align*}
N=\mathrm{\Theta} F&= A A F =\\
&=\big(\lambda x. \lambda y.y (x x y)\big) A F \rightsquigarrow
F (A A F)=F(\mathrm{\Theta} F)=F N,
\end{align*}
{% endtex %}

где $\rightsquigarrow$ обозначает последовательность из нуля или нескольких шагов 
$\beta$-редукции. $\blacksquare$

Теперь $\mathrm{Y}$-комбинатор может быть применен для вычисления значений функций, вызывающих 
сами себя, в среде, не имеющей возможности выполнять именованный рекурсивный вызов или вообще не 
поддерживающей именование объектов.

Например, если требуется вычислить функцию $f= \lambda x.(\ldots f\ldots)$, вызывающую саму себя 
по имени $f$, то можно определить новую функцию $F$, принимающую $f$ как аргумент: 
$F\equiv\lambda f.\lambda x.(\ldots f\ldots)$ (а при использовании индексов де Брёйна или 
бинарного лямбда-исчисления мы можем избавиться и от именованных переменных вовсе). После 
определения $F$ мы можем вычислить $f$ как $f=\mathrm{Y} F$, потому что $f$ есть неподвижная 
точка $F$, т.е., $F f=\lambda x.(\ldots f\ldots)=f$, а $\mathrm{Y} F$, как было сказано выше, 
как раз и находит такую неподвижную точку. Желающие могут непосредственной подстановкой 
убедиться, что в этом случае действительно выполняется $F (\mathrm{Y} F)=\mathrm{Y} F$.

Учитывая универсальность $\lambda$-исчисления и вышеприведенную теорему о неподвижной точке [в 
$\lambda$-исчислении], естественно возникает идея об использовании комбинатора неподвижной точки 
для конструирования квайнов. (См. также [2, 47].)

(Утверждение о существовании комбинатора неподвижной точки практически эквивалентно 
вышеприведенный первой рекурсивной теореме Клини, но выглядит более конкретным.)

## Логическое программирование в ограничениях

В [12, 49] приводится интересный метод генерации квайнов с использованием логического 
программирования. Авторы использовали язык логического программирования miniKanren [52], 
позволяющий написать на нём аналог <<основного уравнения квайнов>> $\llbracket q\rrbracket(x)=q$ 
и дать системе решить его относительно $q.$

С использованием реализации miniKanren, выполненной на языке scheme, квайны можно 
генерировать примерно так (`q.scm` взят из [49]):

```scheme
(load "q.scm")
(run 1 (q) (eval-expo q '() q)))
```

Квайны вычисляются быстро (за секунду) и имеют малые размеры.

(Существует множество реализаций miniKanren и на других языках, e.g., на ECMAScript/JavaScript, 
Python, Ruby, etc.)

## Эволюционные алгоритмы

Крайне интересной представляется потенциальная возможность генерации квайнов с помощью 
генетических алгоритмов. Среди многих проблем, возникающих при генерации программ эволюционными 
методами, выделяется проблема сохранения допустимости или синтаксической <<корректности>> 
программ при действии генетических операторов (кроссовер, мутация).

В этом смысле, одним из наиболее пригодных представлений для инкрементной эволюционной 
генерации, являются искусственные нейронные сети (далее ИНС или нейросети). Будучи сетями 
однотипных нелинейных сумматоров, работа которых зависит от весов связей (синапсов) между ними, 
нейросети продолжают сохранять работоспособность даже при почти случайных 
изменениях/<<повреждениях>> в матрице их весовых коэффициентов. Это довольно сильно 
контрастирует с традиционными языками программирования, программы на которых с гораздо большей 
вероятностью подвержены выходу из строя при малейших необдуманных модификациях их исходного 
текста.

Квайны в виде нейросетей уже известны. В [41] описана ИНС, обучающаяся выводить значения своих 
же синаптических коэффициентов. Я же хотел бы здесь сосредоточится на другом способе генерации 
квайнов, а именно на конструировании программ посредством применения генетических алгоритмов к 
промежуточному представлению на основе нейросетей.

Есть интересный экспериментальный язык Anne, [40], придуманный специально для работы с 
нейросетями и транслятор neuralbf [16, 51] того же автора, преобразующий программу на bf в 
описание рекуррентной ИНС. Последняя работа (кому-то могущая показаться несерьёзной) 
фокусируется на применении генетических алгоритмов для совершенствования и исправления уже 
написанных вручную программ (вместо их генерации без начального приближения).

## Цепные квайны

Назовём *цепным квайном* (или итеративным квайном) с периодом $n$, последовательность $n$ программ
$q_0,\ \ldots,\ q_{n-1}$, такую, что $\forall i\in [0;n[\ \forall x\ \llbracket q_i 
\rrbracket(x) = q_{i+1}$ и $q_n=q_0$.

Можно получить интересное обобщение --- многоязыковой или <<релейный>> квайн --- если заменить в 
только-что данном определении скобки $\llbracket\cdot\rrbracket$ на $\llbracket 
\cdot\rrbracket_{l_i}$, где $\{l_i\}_i$ -- возможно различные языки программирования 
(подразумевается $l_n=l_0$).

**Теорема (без доказательства).**

Цепные квайны существуют для любого периода $n$.

Всякий, кто пытался писать квайны и цепные квайны, не мог не отметить некоторое отличие в 
сложности их написания -- цепные квайны [при $n>1$] обычно проще истинных квайнов (i.e., тоже 
цепных квайнов, но с периодом $n=1$).

Соответственно, не может не возникнуть вопрос о реализуемости полностью автоматического 
преобразования данной последовательности $\{q_i\}_i$ в настоящий квайн $q=\llbracket 
q\rrbracket(x),\ \forall x$.

## Генератор квайнов, не зависимый от языка

В разделе о конструировании квайнов на основе второй рекурсивной теоремы Клини, приводился 
готовый рецепт, алгоритм генерации квайна для конкретного заранее выбранного языка 
программирования. (Похожий алгоритм возможен и в контексте доказательства теоремы Роджерса.) 
Возможно, что слово <<алгоритм>> здесь можно понимать более формально и буквально.

Представляется интересным вопрос о существовании программы $G$, --- <<квайнтификатора>>, --- 
генерирующей квайн на указанном языке $L$ с использованием некоторого количества образцов кода 
на этом языке. Причем и разумной спецификацией языка $L$ и одновременно образцом кода на нём 
может служить интерпретатор языка $L$ (существующий по теореме об универсальной функции).

Чуть более формально задача может быть поставлена так. Пусть дан интерпретатор $I_L$ языка $L$, 
написанный на своем же входном языке, т.е. для любой программы $p$ на языка $L$ выполняется 
$\llbracket I_L\rrbracket_L(p, x)=\llbracket p\rrbracket_L(x)$. Пусть также $I_L$ оттранслирован 
на референсный язык (семантические скобки без индекса) и существует на нём в виде программы 
$I'_L$. В этом случае справедливо $\llbracket I'_L\rrbracket(p, x)=\llbracket p\rrbracket_L(x)$.

Спрашивается, как может выглядеть программа $G$, такая, что $q=\llbracket G\rrbracket (I_L, 
I'_L)$ и $\llbracket I'_L\rrbracket (q, x)=q$? Выше мы видели, что $q$ есть неподвижная точка 
(по Роджерсу) оператора $\mathrm{quote}$. При попытке реализовать $\mathrm{quote}$ выясняется, 
что структура соответствующей программы сильно схожа со структурой интерпретатора. Возможно, это 
сходство можно использовать для написания $G$... Но это требует дальнейшего обдумывания.

Вместо самоинтерпретаторов можно использовать обычно более простые программы, --- 
*специализаторы,* --- реализующие $S^m_n$-функцию, ведь именно она является главным ингредиентом 
(после диагонализации, конечно) в доказательстве теоремы Клини о рекурсии. (В следующих 
сообщениях этот вопрос, возможно, будет исследован более подробно.)

# Заключение

Целью этого сообщения была демонстрация возможности автоматического конструирования квайнов на 
языке редактора sed с использованием доказательства второй рекурсивной теоремы Клини в качестве 
основы. Результат проведенного эксперимента можно считать положительным, хотя *автоматическим* 
такой способ написания квайнов можно назвать только в смысле достаточности запуска единственного 
скрипта `generate.sh` и ликвидации наиболее сложной, и, если можно так выразиться, творческой 
составляющей в конструировании самореплицирующейся системы.

В целом, сообщение уже немного вышло за рамки очерченных целей. Но о квайнах можно сказать 
больше... В следующих сообщениях этой серии.

# Ссылки

<div class="bib">

- [1] <http://www.madore.org/~david/computers/quine.html>
- [2] <http://math.berkeley.edu/~kmill/blog/blog_2018_5_31_universality_quines.html>
- [3] <http://en.wikipedia.org/wiki/Smn_theorem>
- [4] <http://en.wikipedia.org/wiki/partial_evaluation>
- [5] <http://fi.ftmr.info>
- [6] <http://ru.wikipedia.org/wiki/диагональный_аргумент>
- [7] <http://ru.wikipedia.org/wiki/теорема_Кантора>
- [8] <http://ru.wikipedia.org/wiki/проблема_остановки>
- [9] <http://ru.wikipedia.org/wiki/автомат_фон_Неймана>
- [10] <http://ru.wikipedia.org/wiki/зонд_фон_Неймана>
- [11] Jiazhen Cai, Robert Paige, Program derivation by fixed point computation, 1989
- [12] William E.Byrd, Eric Holk, Daniel P.Friedman, miniKanren, live and untagged: Quine generation via relational interpreters, 2012
- [14] S.C.Kleene, Introduction to Meta-Mathematics, 1952
- [15] <en.wikipedia.org/wiki/Quine's_paradox>
- [16] <http://www.domob.eu/projects/neuralbf.php>
- [17] <https://github.com/MakeNowJust/quine/blob/master/quine.sed>
- [18] <https://github.com/MakeNowJust/quine>
- [19] H.Rogers, Theory of Recursive Functions and Effective Computability
- [20] T.A.Hansen, T.Nikolajsen, J.L.Traff, N.D.Jones, Experiments with Implementation of two Theoretical Constructions
- [21] G.Bonfante, M.Kaczmarek, J-Y.Marion, Toward an Abstract Computer Virology
- [22] G.Bonfante, M.Kaczmarek, J-Y.Marion, A Classification of Viruses through Recursion Theorems, 2007
- [23] Julia L. Lawall, Olivier Danvy, Continuation-Based Partial Evaluation
- [24] Anders Bondorf, Improving Binding Times Without Explicit CPS-Conversion
- [25] D.A.Wheeler, Fully Countering Trusting Trust through Diverse Double-Compiling, 2009
- [26] Douglas R.Hofstadter, Goedel, Escher, Bach: an Eternal Golden Braid, 1979
- [27] P.-M. Binder, Theories of almost everything, 2008
- [28] H.G.Rice, Classes of recursively enumerable sets and their decision problems, 1953
- [29] <https://en.wikipedia.org/wiki/Rice_theorem>
- [30] Gary P.Thompson II, The quine page 
   (self-reproducing code), <http://www.nyx.net/~gthompso/quine.htm>
- [31] <http://www.nyx.net/~gthompso/self_kim.txt>
- [32] <http://www.latrobe.edu.au/phimvt/joy>
- [33] <https://gist.github.com/Circiter/7152686>
- [34] <http://en.wikipedia.org/wiki/lambda_calculus>
- [35] Lawrence S.Moss, Recursion Theorems and Self-Replication Via Text Register Machine 
   Programs
- [36] Neil Jones, Computer implementation and application of Kleene's s-m-n and recursion 
   theorem.
- [37] A.Tarski, A lattice theoretical fixpoint theorem and its applications, 1955
- [38] P.Cousot, R.Cousot, Constructive versions of Tarski's fixed point theorems, 1979
- [39] J.Case, S.E.Moelius III, Program Self-Reference in Constructive Scott Subdomains, 2009
- [40] <http://compann.sourceforge.net>
- [41] O.Chang, H.Lipson, Neural Network Quine, 2018
- [42] <http://en.wikipedia.org/wiki/quine>
- [43] F.William Lawvere, Diagonal arguments and cartesian closed categories, 1969
- [44] Noson S.Yanofsky, A Universal Approach to Self-Referential Paradoxes, Incompleteness and 
   Fixed Points, 2003
- [45] Jean-Yves Marion, From Turing machines to computer viruses, 2012
- [46] <https://github.com/Circiter/quine-kleene-generator>
- [47] Kleene Second Recursion Theorem: A Functional Pearl // Proc. ACM 
   Program. Lang., Vol 1, 2018
- [48] Дж. фон Нейман, Теория самовоспроизводящихся автоматов, 1971
- [49] <https://github.com/webyrd/quines>
- [50] В.М.Зюзьков, Теория алгоритмов: Учебное пособие, 2005
- [51] <https://gitlab.com/domob/neuralbf>
- [52] <https://github.com/miniKanren>
- [53] <http://www.michaelwehar.com/quines>
- [54] <http://www.keithschwarz.com/kleene>
- [55] <http://www.nyx.net/~gthompso/quine-1.1.0.tar.gz>
- [56] J.C.Owings младший, Diagonalization and the Recursion Theorem, 1973
- [57] E.Alonso, M.Manzano, Diagonalization and Church's Thesis: Kleene's Homework, 2005

</div>
